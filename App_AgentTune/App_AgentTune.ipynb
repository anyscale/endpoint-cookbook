{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d0d45c6-c66f-4120-8c3f-7f1b51e302e4",
   "metadata": {},
   "source": [
    "# AgentTuning\n",
    "## [AgentTuning](https://thudm.github.io/AgentTuning/) is an attempt to instruction-tune LLMs using interaction trajectories across multiple agent tasks. Evaluation results indicate that AgentTuning enables the agent capabilities of LLMs with robust generalization on unseen agent tasks while remaining good on general language abilities. \n",
    "\n",
    "## In this cookbook, We will show how to use the open-sourced **AgentInstruct** dataset to finetune Anyscale Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4d0e94-3696-4232-bb19-2d7235b39792",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pandas pyarrow s3fs fastparquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f729b9e5-3812-4a2f-8665-526991f34c9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Download AgentInstruct dataset from [Hugging Face](https://huggingface.co/datasets/THUDM/AgentInstruct), and convert the PARQUET file into JSONL format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa31bce8-a764-4dc8-a2b2-6b7e740a831c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Parquet to GPT-format jsonl\n",
    "import pandas as pd\n",
    "import json\n",
    "filenames = ['alfworld-00000-of-00001-302ad687bb3817a4.parquet',\n",
    "             'webshop-00000-of-00001-9f2ae60445e11b4e.parquet',\n",
    "             'mind2web-00000-of-00001-fc25d47330eea0fc.parquet',\n",
    "             'kg-00000-of-00001-9e159f6d0557d229.parquet',\n",
    "             'os-00000-of-00001-971539c34fcc7500.parquet',\n",
    "             'db-00000-of-00001-916a87c4725da8c0.parquet']       \n",
    "             \n",
    "def parquet2jsonl(filename, outfn):\n",
    "    df = pd.read_parquet(filename)\n",
    "    outfile =  open(outfn, 'w')\n",
    "    entry = {}\n",
    "    for row in df['conversations']:\n",
    "        entry['messages']=[]\n",
    "        for msg in row:\n",
    "            if msg['from'] == 'human':\n",
    "                entry['messages'].append({'role':'user','content':msg['value']})\n",
    "            elif msg['from'] == 'gpt':\n",
    "                entry['messages'].append({'role':'assistant','content':msg['value']})\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')\n",
    "\n",
    "for fn in filenames:\n",
    "    filename = '/AGNETINSTRUCT_FOLDER/'+fn\n",
    "    outfn = fn.split('-')[0]+\".jsonl\"\n",
    "    parquet2jsonl(filename, outfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3f13081d-f1f1-4816-a5a4-c9a621f12250",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Combine into one whole jsonl file\n",
    "infiles=['alfworld.jsonl','webshop.jsonl','mind2web.jsonl','kg.jsonl','os.jsonl','db.jsonl']\n",
    "outfile =  open('agentinstruct_all.jsonl', 'w')\n",
    "for ifile in infiles:\n",
    "    infile = open(ifile,'r')\n",
    "    for row in infile:\n",
    "        entry = json.loads(row)\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f77bb392-4859-48ed-82b7-d495313154d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## split into train and val datasets\n",
    "DATA_PATH = \"agentinstruct_all.jsonl\"\n",
    "# Load the dataset\n",
    "with open(DATA_PATH, 'r', encoding='utf-8') as f:\n",
    "    items = [json.loads(line) for line in f]\n",
    "with open('agentinstruct_train.jsonl', 'w') as outfile:\n",
    "    for i, entry in enumerate(items):\n",
    "        if i%5:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')\n",
    "with open('agentinstruct_val.jsonl', 'w') as outfile:\n",
    "    for i, entry in enumerate(items):\n",
    "        if i%5==0:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a331d7-85b8-4736-a2f5-c0df3140aad5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Data Validation check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad1e1f9-87ae-4817-8cfa-24cfa439aff1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from finetune_utils import finetune_check\n",
    "finetune_check('./agentinstruct_train.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc69964-3118-4dd9-8f8e-458b1e6bad1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Finetune with training and val datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "752b42f4-3b42-4ffa-b167-07fda313b13d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject id=eftjob_g7fumcde5n1tcbrwfwz2brlal4 at 0x7fd763f928b0> JSON: {\n",
       "  \"result_files\": [],\n",
       "  \"trained_tokens\": null,\n",
       "  \"hyperparameters\": {\n",
       "    \"n_epochs\": null,\n",
       "    \"context_length\": null\n",
       "  },\n",
       "  \"training_file\": \"file_67mtyt94frq7qtzcyirplyvlnf\",\n",
       "  \"validation_file\": \"file_8fstlskmnmbhsymsl1g4ava7zj\",\n",
       "  \"model\": \"meta-llama/Llama-2-13b-chat-hf\",\n",
       "  \"id\": \"eftjob_g7fumcde5n1tcbrwfwz2brlal4\",\n",
       "  \"created_at\": \"2023-10-24T01:41:15.123886+00:00\",\n",
       "  \"finished_at\": null,\n",
       "  \"fine_tuned_model\": \"meta-llama/Llama-2-13b-chat-hf:agentinstruct:8VRVuzi\",\n",
       "  \"status\": \"pending\",\n",
       "  \"error\": null,\n",
       "  \"creator_id\": \"user_ymu3y6unv8k55r54ifgsdk533j\"\n",
       "}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from finetune_utils import finetune_run\n",
    "finetune_run('./agentinstruct_train.jsonl','./agentinstruct_val.jsonl',\n",
    "             token='ANYSCALE_API_TOKEN', model='meta-llama/Llama-2-13b-chat-hf', suffix='agentinstruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "88b5c306-c581-40da-ac14-b358d88a38c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FineTuningJob id=eftjob_g7fumcde5n1tcbrwfwz2brlal4 at 0x7fd1228d3e00> JSON: {\n",
       "  \"result_files\": [\n",
       "    \"file_8vpyqr9x6iwlxzsvhha53jk4ta\"\n",
       "  ],\n",
       "  \"trained_tokens\": null,\n",
       "  \"hyperparameters\": {\n",
       "    \"n_epochs\": null,\n",
       "    \"context_length\": null\n",
       "  },\n",
       "  \"training_file\": \"file_67mtyt94frq7qtzcyirplyvlnf\",\n",
       "  \"validation_file\": \"file_8fstlskmnmbhsymsl1g4ava7zj\",\n",
       "  \"model\": \"meta-llama/Llama-2-13b-chat-hf\",\n",
       "  \"id\": \"eftjob_g7fumcde5n1tcbrwfwz2brlal4\",\n",
       "  \"created_at\": \"2023-10-24T01:41:15.123886+00:00\",\n",
       "  \"finished_at\": null,\n",
       "  \"fine_tuned_model\": \"meta-llama/Llama-2-13b-chat-hf:agentinstruct:8VRVuzi\",\n",
       "  \"status\": \"running\",\n",
       "  \"error\": null,\n",
       "  \"creator_id\": \"user_ymu3y6unv8k55r54ifgsdk533j\"\n",
       "}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "## Check funetune status\n",
    "openai.FineTuningJob.retrieve(\"eftjob_g7fumcde5n1tcbrwfwz2brlal4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4671d3ff-57be-4db2-bd3c-8fed94e43b66",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. Run inference on finetuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a8970fb-032a-4f50-982b-2044c311aa61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"meta-llama/Llama-2-13b-chat-hf:agentinstruct:8VRVuzi-2ce2cd09a92398cddd31fea685d13fe6\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1698196096,\n",
      "  \"model\": \"meta-llama/Llama-2-13b-chat-hf:agentinstruct:8VRVuzi\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \" I'll be happy to help with your query. Please provide the query you'd like me to execute. \"\n",
      "      },\n",
      "      \"index\": 0,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 11,\n",
      "    \"completion_tokens\": 25,\n",
      "    \"total_tokens\": 36\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "content=\"your query here\"\n",
    "OPENAI_API_BASE=\"https://console.endpoints.anyscale.com/m/v1\"\n",
    "OPENAI_API_KEY=\"ANYSCALE_API_TOKEN\"\n",
    "chat_completion = openai.ChatCompletion.create(\n",
    "    api_base=OPENAI_API_BASE,\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    model=\"meta-llama/Llama-2-13b-chat-hf:agentinstruct:8VRVuzi\",\n",
    "    messages=[{\"role\": \"user\", \"content\": content}],\n",
    "    temperature=0\n",
    ")\n",
    "print(chat_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87502986-a316-47c8-931b-81ea07ac0814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
