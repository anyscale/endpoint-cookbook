{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c4df44-8e29-4326-a0f2-61232347de85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install -q arize langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0b24bd-665a-4b0f-ac46-7fe03528a4ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Set Arize credentials and define the callback handler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4fb005-eb38-4b9c-926e-075a90ff58ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.callbacks.arize_callback import ArizeCallbackHandler\n",
    "\n",
    "SPACE_KEY = \"YOUR_SPACE_KEY\"\n",
    "API_KEY =  \"YOUR_API_KEY\"\n",
    "\n",
    "if SPACE_KEY == \"YOUR_SPACE_KEY\" or API_KEY == \"YOUR_API_KEY\":\n",
    "    raise ValueError(\"‚ùå CHANGE SPACE AND API KEYS\")\n",
    "\n",
    "# Define callback handler for Arize\n",
    "arize_chat_callback = ArizeCallbackHandler(\n",
    "model_id=\"anyscale-langchain-demo\",\n",
    "model_version=\"1.0\",\n",
    "SPACE_KEY=SPACE_KEY,\n",
    "API_KEY=API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec66d8ad-fa96-49c3-a1f5-05bf14903f01",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Use LangChain to define prompt messages, get models, and directly call Arize callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3bb7e2-563c-4360-a26d-2208fed60d58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from langchain.chat_models import ChatAnyscale\n",
    "\n",
    "ANYSCALE_ENDPOINT_TOKEN = \"YOUR_ENDPOINT_TOKEN\"\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful AI that shares everything you know.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"How to evaluate the value of a NFL team\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "chats = {\n",
    "    model: ChatAnyscale(anyscale_api_key=ANYSCALE_ENDPOINT_TOKEN,\n",
    "                        model_name=model, \n",
    "                        temperature=1.0)\n",
    "    for model in ChatAnyscale.get_available_models(anyscale_api_key=ANYSCALE_ENDPOINT_TOKEN)\n",
    "}\n",
    "\n",
    "for model, chat in chats.items():\n",
    "    response = chat.predict_messages(messages, callbacks=[arize_chat_callback])\n",
    "    print(model, \"\\n\", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e851b79e-c0e7-47d9-9b5d-69a9c885faa7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Use callback manager for Arize integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a37d9f-ed46-4abf-b57c-9f98a71d23b0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "manager = CallbackManager([StdOutCallbackHandler(), arize_chat_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bef96c-6d0f-4ad6-a446-d298afb74744",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"You are a playwrighter. Given the title of play, it is your job to write a synopsis for that title.\n",
    "Title: {title}\n",
    "Playwright: This is a synopsis for the above play:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"title\"], template=template)\n",
    "synopsis_chain = LLMChain(llm=chat, prompt=prompt_template, callback_manager=manager)\n",
    "\n",
    "\n",
    "overall_chain = SimpleSequentialChain(\n",
    "   chains=[synopsis_chain], callback_manager=manager\n",
    ")\n",
    "\n",
    "\n",
    "test_prompts = [\n",
    "   {\n",
    "       \"input\": \"documentary about pandas who are about be extinct because of global warming\"\n",
    "   },\n",
    "   {\"input\": \"once upon a time in hollywood\"},\n",
    "   {\"input\": \"the best model observability tooling\"},\n",
    "   {\"input\": \"childrens play about a frog living in an alpine lake just discovered by humans\"},\n",
    "   {\"input\": \"utopian society being disrupted by new AI\"},\n",
    "]\n",
    "overall_chain.apply(test_prompts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
