{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1f7809a",
   "metadata": {},
   "source": [
    "# Using Anyscale Endpoints to create a Streaming Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c4df44-8e29-4326-a0f2-61232347de85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip3 install -q openai (openai > 1.0)\n",
    "!pip show openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee0b24bd-665a-4b0f-ac46-7fe03528a4ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Define your Chat Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d4fb005-eb38-4b9c-926e-075a90ff58ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "class OpenAIChatAgent:\n",
    "    def __init__(self, model: str):\n",
    "    #In this simple example, we do not modify the past conversation.\n",
    "    #Eventually you will run out of context window, but this should be enough for a 30-step conversation\n",
    "    #You need to either trim the message history or summarize it for longer conversations\n",
    "        self.message_history = []\n",
    "        self.model = model\n",
    "\n",
    "    def process_input(self, input: str):\n",
    "        self.update_message_history(input)      \n",
    "        \n",
    "        openai.base_url = \"https://api.endpoints.anyscale.com/v1\" +'/'\n",
    "        openai.api_key = ANYSCALE_ENDPOINT_TOKEN\n",
    "                \n",
    "        response = openai.chat.completions.create(\n",
    "           model = self.model,\n",
    "           messages = self.message_history,\n",
    "           stream = True\n",
    "        )\n",
    "        words = ''\n",
    "        for tok in response:\n",
    "            delta = tok.choices[0].delta          \n",
    "            if not delta: # End token \n",
    "                self.message_history.append({\n",
    "                    'role': 'assistant',\n",
    "                    'content': words\n",
    "                })\n",
    "                break\n",
    "            elif delta.content:\n",
    "                words += delta.content\n",
    "                yield delta.content \n",
    "            else: \n",
    "                continue\n",
    "\n",
    "    def update_message_history(self, inp):\n",
    "        self.message_history.append({\n",
    "            'role': 'user',\n",
    "            'content': inp\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec66d8ad-fa96-49c3-a1f5-05bf14903f01",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Instantiate a chat session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf673fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "ANYSCALE_ENDPOINT_TOKEN = \"esecret_xxxxxxxxxxxxxxxxxx\"\n",
    "\n",
    "agent = OpenAIChatAgent(\"meta-llama/Llama-2-70b-chat-hf\")\n",
    "sys.stdout.write(\"Let's have a chat. (Enter `quit` to exit)\\n\") \n",
    "while True: \n",
    "    sys.stdout.write('> ')\n",
    "    inp = input()\n",
    "    if inp == 'quit':\n",
    "        break\n",
    "    for word in agent.process_input(inp):\n",
    "        sys.stdout.write(word)\n",
    "        sys.stdout.flush()\n",
    "    sys.stdout.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
